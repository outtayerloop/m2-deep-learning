{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3. Dropout.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "58bbd9a2-f1e2-45f3-a3d0-de076c26cc11",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPUhfWHpq_cO"
      },
      "source": [
        "## le dropout \n",
        "\n",
        "Le dropout est une méthode de régularisation qui consiste à mettre la sortie de certains neurones à zéro pendant l'entraînement de manière aléatoire.\n",
        "\n",
        "On peut voir ça comme un entraînement avec handicap : si vous êtes capable de tirer à l'arc en fermant un oeil, vous serez peut être meilleur quand vous avez vos deux yeux. \n",
        "\n",
        "Keras propose une couche Dropout qui permet d'appliquer du dropout sur une couche au choix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvXV3xYlq_cX"
      },
      "source": [
        "Reprendre le réseau de l'exercice précédent avec 2 couches de convolutions et 2 couches denses. \n",
        "\n",
        "Ajouter une couche de dropout entre les deux couches convolutionnelles avec p=0.05 \n",
        "Entraîner le réseau. \n",
        "\n",
        "Faire en sorte d'afficher l'accuracy sur le train et le test et la comparer à un réseau sans dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuaiy6HCsoFg"
      },
      "source": [
        "Where should we place Dropout layers ?\n",
        "- https://stats.stackexchange.com/questions/240305/where-should-i-place-dropout-layers-in-a-neural-network/317313#317313\n",
        "- not very well known for the moment but one of the most current practices is to put them in the Dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS0FQjnmq_cZ",
        "outputId": "07819b21-3125-49ad-f9c8-e1af67583361"
      },
      "source": [
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "\n",
        "data = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R21_9orUrT4C"
      },
      "source": [
        "train, test = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i1Q5M2qrVPt"
      },
      "source": [
        "X_train, y_train = train\n",
        "X_test, y_test = test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GFPKkwArXUQ"
      },
      "source": [
        "images_count, image_height, image_width, color_count = X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "folvO6sNrnbR"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq-vgn0lrpWh",
        "outputId": "454f9963-c08d-4c3a-c6e0-6c66ff87643b"
      },
      "source": [
        "import numpy as np\n",
        "class_values = np.unique(data[0][1]) # or else len(set(y_train))\n",
        "class_count = len(np.array(class_values))\n",
        "class_count, class_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apbYrS46rr7-"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW4OlvTHtoML"
      },
      "source": [
        "### Without dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mdv6frCths6"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX_G4XO4tj41"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGt__gDntlAC",
        "outputId": "24fcdfd7-4e03-4d05-c794-689eec581570"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 27s 10ms/step - loss: 1.8243 - accuracy: 0.3434 - val_loss: 1.6936 - val_accuracy: 0.3877\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.5339 - accuracy: 0.4566 - val_loss: 1.4297 - val_accuracy: 0.4939\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3707 - accuracy: 0.5115 - val_loss: 1.3126 - val_accuracy: 0.5389\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.2390 - accuracy: 0.5610 - val_loss: 1.2484 - val_accuracy: 0.5556\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.1268 - accuracy: 0.5980 - val_loss: 1.1754 - val_accuracy: 0.5817\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.0222 - accuracy: 0.6368 - val_loss: 1.1424 - val_accuracy: 0.5984\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9213 - accuracy: 0.6746 - val_loss: 1.1760 - val_accuracy: 0.5791\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.8175 - accuracy: 0.7117 - val_loss: 1.2409 - val_accuracy: 0.5876\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.7055 - accuracy: 0.7541 - val_loss: 1.1635 - val_accuracy: 0.6208\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.5907 - accuracy: 0.7959 - val_loss: 1.2457 - val_accuracy: 0.6089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1265bae690>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtQehLF0trgT"
      },
      "source": [
        "### With dropout (p = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC0FTkK6rtfv"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.05))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y9R9RucsFP0"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDZFHuPGsFu6",
        "outputId": "d9730473-8de3-4b6c-ef6b-12df97ff7f0c"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8078 - accuracy: 0.3542 - val_loss: 1.6930 - val_accuracy: 0.3997\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.5058 - accuracy: 0.4642 - val_loss: 1.4158 - val_accuracy: 0.4876\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3525 - accuracy: 0.5154 - val_loss: 1.3354 - val_accuracy: 0.5128\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2357 - accuracy: 0.5616 - val_loss: 1.2787 - val_accuracy: 0.5487\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1288 - accuracy: 0.6008 - val_loss: 1.1717 - val_accuracy: 0.5861\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0257 - accuracy: 0.6362 - val_loss: 1.1751 - val_accuracy: 0.5859\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9190 - accuracy: 0.6785 - val_loss: 1.1157 - val_accuracy: 0.6113\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8065 - accuracy: 0.7188 - val_loss: 1.1094 - val_accuracy: 0.6187\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6927 - accuracy: 0.7573 - val_loss: 1.2023 - val_accuracy: 0.6042\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5748 - accuracy: 0.7984 - val_loss: 1.2451 - val_accuracy: 0.6100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11edbbaad0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mettre un dropout de 0.05 a l'air d'améliorer très légèrement les performances du modèle en termes de loss et d'accuracy"
      ],
      "metadata": {
        "id": "qKL6F8OvJ33J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeXGz8isq_ca"
      },
      "source": [
        "Entraîner à la suite plusieurs réseau en faisant croitre de manière progressive le dropout prendre p = 0.1, 0.2, 0.5, 0.8 \n",
        "\n",
        "\n",
        "Que constatez vous sur l'évolution des performances du modèles sur le train et le test ? \n",
        "\n",
        "Qu'en déduisez vous sur le choix du dropout ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7hg9bbVuMW8"
      },
      "source": [
        "### With dropout (p = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOChq5gkuPPE"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.1))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2WAA64KuR-c"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0vydnBIq_cb",
        "outputId": "c67b411f-5dfa-4ea7-9e5f-7109b4c65bac"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 17s 10ms/step - loss: 1.8137 - accuracy: 0.3501 - val_loss: 1.5784 - val_accuracy: 0.4318\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5169 - accuracy: 0.4608 - val_loss: 1.4346 - val_accuracy: 0.4900\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3575 - accuracy: 0.5118 - val_loss: 1.3961 - val_accuracy: 0.5081\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2355 - accuracy: 0.5619 - val_loss: 1.2846 - val_accuracy: 0.5435\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1207 - accuracy: 0.6015 - val_loss: 1.1900 - val_accuracy: 0.5777\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0149 - accuracy: 0.6406 - val_loss: 1.1060 - val_accuracy: 0.6060\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9129 - accuracy: 0.6789 - val_loss: 1.1027 - val_accuracy: 0.6083\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8074 - accuracy: 0.7162 - val_loss: 1.1104 - val_accuracy: 0.6210\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7011 - accuracy: 0.7546 - val_loss: 1.0798 - val_accuracy: 0.6303\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5893 - accuracy: 0.7939 - val_loss: 1.1853 - val_accuracy: 0.6223\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11ed9d9290>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout de 0.1 améliore un peu plus les performances que le dropout de 0.05"
      ],
      "metadata": {
        "id": "nTYldKF2KBYF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcmHAKS5uUsF"
      },
      "source": [
        "### With dropout (p = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7crr2XIuXOi"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.2))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JExIw6uYCn"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDY2KrtYuYxs",
        "outputId": "71153f2a-7098-4ad0-e99e-660ce1b34deb"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8505 - accuracy: 0.3368 - val_loss: 1.7552 - val_accuracy: 0.3675\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.5354 - accuracy: 0.4551 - val_loss: 1.4118 - val_accuracy: 0.4995\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3758 - accuracy: 0.5098 - val_loss: 1.4115 - val_accuracy: 0.4919\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2594 - accuracy: 0.5523 - val_loss: 1.2945 - val_accuracy: 0.5335\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1527 - accuracy: 0.5909 - val_loss: 1.2029 - val_accuracy: 0.5728\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0502 - accuracy: 0.6287 - val_loss: 1.1727 - val_accuracy: 0.5881\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9517 - accuracy: 0.6638 - val_loss: 1.1436 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.8579 - accuracy: 0.7010 - val_loss: 1.1064 - val_accuracy: 0.6134\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.7625 - accuracy: 0.7337 - val_loss: 1.1166 - val_accuracy: 0.6213\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6625 - accuracy: 0.7669 - val_loss: 1.1612 - val_accuracy: 0.6226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11ed862810>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout de 0.2 a l'air de continuer d'augmenter les performances du modèle"
      ],
      "metadata": {
        "id": "cNkg4y0CKje9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzTsJUbbuaph"
      },
      "source": [
        "### With dropout (p = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im3e4yXBudg6"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.5))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnCLtF9uee4"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl2Tul28ugG3",
        "outputId": "d9aca583-9307-413b-edfe-01db6ef013fd"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 17s 10ms/step - loss: 1.8722 - accuracy: 0.3250 - val_loss: 1.6958 - val_accuracy: 0.3991\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.5289 - accuracy: 0.4539 - val_loss: 1.5629 - val_accuracy: 0.4318\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3753 - accuracy: 0.5091 - val_loss: 1.3606 - val_accuracy: 0.5104\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2777 - accuracy: 0.5439 - val_loss: 1.2836 - val_accuracy: 0.5430\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1913 - accuracy: 0.5762 - val_loss: 1.2125 - val_accuracy: 0.5621\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1066 - accuracy: 0.6068 - val_loss: 1.1887 - val_accuracy: 0.5735\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0234 - accuracy: 0.6380 - val_loss: 1.1021 - val_accuracy: 0.6079\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9468 - accuracy: 0.6650 - val_loss: 1.1160 - val_accuracy: 0.6117\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.8719 - accuracy: 0.6914 - val_loss: 1.0902 - val_accuracy: 0.6232\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.7929 - accuracy: 0.7199 - val_loss: 1.0910 - val_accuracy: 0.6279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11ed739990>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout de 0.5 commence par contre à dégrader les performances du modèle"
      ],
      "metadata": {
        "id": "tZwQPQd6KrBM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFV9D7hmuhVz"
      },
      "source": [
        "### With dropout (p = 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0_Y8cxKukiX"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.8))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiA6ITw4ulSA"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27KPiESumsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125e1227-f8fb-4392-9f00-61287a1afea4"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8907 - accuracy: 0.3194 - val_loss: 1.8456 - val_accuracy: 0.3528\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.6039 - accuracy: 0.4304 - val_loss: 1.5682 - val_accuracy: 0.4417\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4614 - accuracy: 0.4759 - val_loss: 1.4334 - val_accuracy: 0.4880\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3726 - accuracy: 0.5094 - val_loss: 1.4542 - val_accuracy: 0.4833\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3042 - accuracy: 0.5340 - val_loss: 1.3435 - val_accuracy: 0.5266\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2426 - accuracy: 0.5571 - val_loss: 1.2475 - val_accuracy: 0.5667\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1842 - accuracy: 0.5774 - val_loss: 1.2802 - val_accuracy: 0.5491\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1306 - accuracy: 0.5985 - val_loss: 1.2120 - val_accuracy: 0.5720\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0732 - accuracy: 0.6158 - val_loss: 1.2275 - val_accuracy: 0.5719\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0231 - accuracy: 0.6371 - val_loss: 1.1252 - val_accuracy: 0.6094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11ec26d950>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout de 0.8 continue de dégrader les performances du modèle (ce qui semble peut-être logique si on drop 80% des neurones de convolution)"
      ],
      "metadata": {
        "id": "c3VECD9KRx4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un dropout à 1 va totalement shut down le modèle vu que la couche précédente est complètement déconnectée de la couche suivante, cependant on peut expérimenter et trouver le dropout maximal à partir duquel on aura amélioré les performances du modèle au maximum en limitant au plus l'overfitting."
      ],
      "metadata": {
        "id": "ac6Ljo5kSCS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus : remettre p=0.05 pour le dropout de la couche convolutionnelle et ajouter également du dropout dans les couches dense. Mettez des valeurs un peu plus importantes que dans la couche convolutionnelle.\n",
        "\n",
        "Quels sont les résultats ?"
      ],
      "metadata": {
        "id": "2Flyj6V6SZvy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZOW2BhWSfkY"
      },
      "source": [
        "### With dropout (p = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9bdcP3dSfkZ"
      },
      "source": [
        "bigger_model = Sequential()\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3], input_shape=[image_height, image_width, color_count]))\n",
        "bigger_model.add(Dropout(rate=0.05))\n",
        "bigger_model.add(Conv2D(32, activation='relu', kernel_size=[3,3]))\n",
        "bigger_model.add(Flatten())\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dropout(rate=0.15))\n",
        "bigger_model.add(Dense(units=300, activation='relu'))\n",
        "bigger_model.add(Dropout(rate=0.15))\n",
        "bigger_model.add(Dense(units=class_count, activation='softmax')) # as many neurones as classes\n",
        "# softmax normalizes the model's outputs so that it looks like a proba distribution with Sum(output_i) = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbjf9MSmSfka"
      },
      "source": [
        "bigger_model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "# categorical_crossentropy : used when class values are already one-hot-encoded\n",
        "# sparse_categorical_crossentropy : used when class values are not already one-hot-encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06194dc6-7afc-4194-92bd-e5f9c723a257",
        "id": "j6Ki8EY_Sfkb"
      },
      "source": [
        "bigger_model_history = bigger_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "bigger_model_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 17s 10ms/step - loss: 1.8555 - accuracy: 0.3311 - val_loss: 1.6219 - val_accuracy: 0.4270\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5310 - accuracy: 0.4514 - val_loss: 1.3814 - val_accuracy: 0.5057\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3705 - accuracy: 0.5098 - val_loss: 1.3231 - val_accuracy: 0.5238\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2417 - accuracy: 0.5551 - val_loss: 1.2471 - val_accuracy: 0.5523\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1424 - accuracy: 0.5926 - val_loss: 1.2486 - val_accuracy: 0.5594\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0517 - accuracy: 0.6264 - val_loss: 1.1379 - val_accuracy: 0.6031\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9651 - accuracy: 0.6583 - val_loss: 1.0578 - val_accuracy: 0.6284\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8766 - accuracy: 0.6908 - val_loss: 1.0282 - val_accuracy: 0.6431\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7878 - accuracy: 0.7212 - val_loss: 1.0399 - val_accuracy: 0.6426\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7004 - accuracy: 0.7536 - val_loss: 1.0477 - val_accuracy: 0.6424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11ed51de50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mettre un dropout de 0.05 a l'air d'améliorer très légèrement les performances du modèle en termes de loss et d'accuracy"
      ],
      "metadata": {
        "id": "kqdyZ3cPSfkd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD-0tvD6Sfkd"
      },
      "source": [
        "Entraîner à la suite plusieurs réseau en faisant croitre de manière progressive le dropout prendre p = 0.1, 0.2, 0.5, 0.8 \n",
        "\n",
        "\n",
        "Que constatez vous sur l'évolution des performances du modèles sur le train et le test ? \n",
        "\n",
        "Qu'en déduisez vous sur le choix du dropout ?\n"
      ]
    }
  ]
}